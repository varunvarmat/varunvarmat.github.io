 
          <!-- motion type Paper 
          <tr onmouseout="motiontype_stop()" onmouseover="motiontype_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='motiontype_image'>
                  <img src='images/motiontype_before.png' width="250"></div>
                <img src='images/motiontype_after.png' width="250">
              </div>
              <script type="text/javascript">
                function motiontype_start() {
                  document.getElementById('motiontype_image').style.opacity = "1";
                }
                function motiontype_stop() {
                  document.getElementById('motiontype_image').style.opacity = "0";
                }
                motiontype_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.01015">
                <papertitle><font size="5">Spatio-Temporal Video Representation Learning via motion type classification</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Gaurav Ramola,
              Ranajit Saha,
              Ravi Kini,
              Aniket Rege,
              Sudha Velusamy
              </font> 
              <br>
              <Strong>ICCVW - SRVU, 2021</Strong> 
              <br>
              <a href="https://arxiv.org/abs/2110.01015">[paper]</a>
              <p style="text-align: justify;"> 
                In this paper, we propose a novel approach for understanding object motions via motion type classification.
                The proposed motion type classifier predicts a motion type for the video based on the trajectories of the objects present. 
                Our classifier assigns a motion type for the given video from the following five primitive motion classes: linear, projectile, oscillatory, local and random. 
                We demonstrate that the representations learned from the motion type classification generalizes well for the challenging downstream task of video retrieval. 
                Further, we proposed a recommendation system for video playback style based on the motion type classifier predictions.
              </p>
            </td>
          </tr>		
          --> 

          <!-- fabsoften Paper 
          <tr onmouseout="fabsoften_stop()" onmouseover="fabsoften_start()">
            <td style="padding:50px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='fabsoften_image'>
                  <img src='images/fabsoften_before.png' width="140"></div>
                <img src='images/fabsoften_after.png' width="140">
              </div>
              <script type="text/javascript">
                function fabsoften_start() {
                  document.getElementById('fabsoften_image').style.opacity = "1";
                }
                function fabsoften_stop() {
                  document.getElementById('fabsoften_image').style.opacity = "0";
                }
                fabsoften_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Velusamy_FabSoften_Face_Beautification_via_Dynamic_Skin_Smoothing_Guided_Feathering_and_CVPRW_2020_paper.pdf">
                <papertitle><font size="5">FabSoften: Face Beautification via Dynamic Skin Smoothing, Guided
                  Feathering, and Texture Restoration</font></papertitle>
              </a>
              <br>
              <font size="3">
              Sudha Velusamy,
              Rishubh Parihar,
              Ravi Kini,               
              Aniket Rege
              </font>
              <br>
              <Strong>CVPRW - NTIRE, 2020</Strong>
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Velusamy_FabSoften_Face_Beautification_via_Dynamic_Skin_Smoothing_Guided_Feathering_and_CVPRW_2020_paper.pdf">pdf</a>
              <p style="text-align: justify;"> 
                We propose a real-time face softening approach that smooths blemishes in the facial skin region, followed by a wavelet band manipulation to restore
                the underlying skin texture, which produces a highly appealing ‘beautified’ face that retains its natural appearance.
              </p>
            </td>
          </tr>		 
          --> 

          <!-- makeup Paper 
          <tr onmouseout="makeup_stop()" onmouseover="makeup_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='makeup_image'>
                  <img src='images/makeup_before.png' width="250"></div>
                <img src='images/makeup_after.png' width="250">
              </div>
              <script type="text/javascript">
                function makeup_start() {
                  document.getElementById('makeup_image').style.opacity = "1";
                }
                function makeup_stop() {
                  document.getElementById('makeup_image').style.opacity = "0";
                }
                makeup_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/pdf/10.1145/3293353.3293385">
                <papertitle><font size="5">Scene Adaptive Cosmetic Makeup Transfer</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Aniket Dashpute,
              Prem Kalra
              </font>
              <br>
              <Strong>Undergrduate Thesis</Strong>
              <br>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3293353.3293385">pdf</a>

              <p style="text-align: justify;"> 
                Given a source and a target image transferring makeup from the source image to the target image.
                The transferred makeup should blend in the scene to provide natural look. To this end, we have developed
                a complete framework which firstly relights the subject image to match the illumination of the target image. 
                We have generated 3D face models from single image and used them for realistic relighting. Following that 
                layer wise decomposition is done for relit source and target image and blending is done within corresponding layers
                to transfer makeup. Finally we have additional modules in our framework to add facial accessories. 
                As we have generated 3D models of the source and target faces we were able to add accessories directly on 3D models 
                which resulted in natural looking output.
              </p>
            </td>
          </tr>	
          --> 	


          <!-- pixeltransformer Paper 
          <tr onmouseout="pixeltransformer_stop()" onmouseover="pixeltransformer_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='pixeltransformer_image'>
                  <img src='images/pixeltransformer_before.png' width="250"></div>
                <img src='images/pixeltransformer_after.png' width="250">
              </div>
              <script type="text/javascript">
                function pixeltransformer_start() {
                  document.getElementById('pixeltransformer_image').style.opacity = "1";
                }
                function pixeltransformer_stop() {
                  document.getElementById('pixeltransformer_image').style.opacity = "0";
                }
                pixeltransformer_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="None">
                <papertitle><font size="5">Image enhancement using pixel-transformer</font></papertitle>
              </a>
              <br>
              <font size="3">
              Ankit Dhiman,
              Rishubh Parihar
              </font>
              <br> 
              <p style="text-align: justify;"> 
              We empirically validate a generative model - PixelTrans- former, which infers distribution of the spatial signal given a sparse set of input samples
              ex. image from the few ob- served pixels. We tested the method under two scenarios; when sampler polls from 1.) a noisy representation and 2.) a low-frequency representation of the underlying spatial signal. Also, we evaluated the model for the different number of encoder and decoder layers. We use the Cifar10[1] dataset for all our experiments.
              </p>
            </td>
          </tr>		
          --> 

          <!-- climbers Project 
          <tr onmouseout="climbers_stop()" onmouseover="climbers_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='climbers_image'>
                  <img src='images/climbers_before.png' width="250"></div>
                <img src='images/climbers_after.png' width="250">
              </div>
              <script type="text/javascript">
                function climbers_start() {
                  document.getElementById('climbers_image').style.opacity = "1";
                }
                function climbers_stop() {
                  document.getElementById('climbers_image').style.opacity = "0";
                }
                climbers_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="None">
                <papertitle><font size="5">Probabilistic creation and rendering of climbing plants</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Aniket Dashpute
              </font>
              <br>
              <p style="text-align: justify;"> 
              Implemented a climbing heuristic to render climbers on required objects in a scene to enhance content creation
              for computer graphics applications. Built a graph which is a minimal abstract representation of plant for production
              of leaves and branches. Traversed the nodes in graph with geometry with materials and textures that can be rendered
              </p>
            </td>
          </tr>		
          --> 
           

          <!-- frog Project 
          <tr onmouseout="frog_stop()" onmouseover="frog_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='frog_image'>
                  <img src='images/frog_before.png' width="250"></div>
                <img src='images/frog_after.png' width="250">
              </div>
              <script type="text/javascript">
                function frog_start() {
                  document.getElementById('frog_image').style.opacity = "1";
                }
                function frog_stop() {
                  document.getElementById('frog_image').style.opacity = "0";
                }
                frog_stop()
            </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="None">
                <papertitle><font size="5">Hierarchical Modelling of 3D animatable frog and key-frame animation</font></papertitle> 
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Aniket Dashpute
              </font>
              <br>
              <p style="text-align: justify;"> 
              Modeled a frog to be represented as a hierarchical model with an articulated structure
              Created animation module by interpolating key frames with diffuse, specular and ambient components
              Made an interactive game with multiple frogs which run behind use controlled insects
              </p>
            </td>
          </tr>
          --> 		

          <!-- raytracer Project 
          <tr onmouseout="raytracer_stop()" onmouseover="raytracer_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='raytracer_image'>
                  <img src='images/raytracer_before.png' width="250"></div>
                <img src='images/raytracer_after.png' width="250">
              </div>
              <script type="text/javascript">
                function raytracer_start() {
                  document.getElementById('raytracer_image').style.opacity = "1";
                }
                function raytracer_stop() {
                  document.getElementById('raytracer_image').style.opacity = "0";
                }
                raytracer_stop()
            </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="None">
                <papertitle><font size="5">Recursive ray tracer for rendering simplistic scenes</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Aniket Dashpute
              </font>
              <br>

              <p></p> 
              <p style="text-align: justify;"> 
                Implemented recursive ray tracing to generate an image of virtually generated 3D model by tracing path of light through pixels
                Implemented global illumination model with reflection, refraction & shadows and local illumination model with diffuse, specular and ambient components
              </p>
            </td>
          </tr>		
          --> 
       

          <!-- Experience both professional and academnics 
          <br>
          <p>
          </p>
          <table style="width:100%;border:0px;border-spacing:50px;border-collapse:separate;margin-right:center;margin-left:center;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading><font size="6">Experience</font></heading>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        -->

          <!-- PhD 
          <tr onmouseout="phd_stop()" onmouseover="phd_start()" style="margin-top: -20px;">
            <td style="padding: 20px; width: 10%; vertical-align: middle; position: relative; left: 50px;">
              <div class="one">
                <div class="two" id='iisc_logo'>
                  <img src='images/iisc_logo.jpeg' width="80"> 
                </div>
              </div>
            </td>
            <td style="padding:0px; width: 100%; vertical-align: top; position: relative; left: -100px;">
              <a href="None"> 
                <papertitle><font size="4">Indian Institute of Science, Bangalore</font></papertitle>
              </a>
              <br>
              <strong>Ph.D in Engineering, Department of Computational and Data Sciences</strong>
              <br>
              <em>August 2021 - Current</em>
            </td>
          </tr>
          --> 

          
        <!-- Sharechat 
          <tr onmouseout="sc_stop()" onmouseover="sc_start()" style="margin-top:-40px">
            <td style="padding:20px;width:10%;vertical-align:middle;position:relative;left:50px">
              <div class="one">
                <div class="two" id='sc_logo'>
                  <img src='images/sc_logo.png' width="80"></div>
              </div>
            </td>
            <td style="padding:0px;width:100%;vertical-align:top;position:relative;left:-100px">
              <a href="None">
                <papertitle><font size="4">ShareChat</font></papertitle>
              </a>
              <br>
              <strong>Data Scientist</strong>
              <br>
              <em>October 2020 - July 2021</em> 
            </td>
          </tr>		 
          --> 

          <!-- Samsung 
          <tr onmouseout="samsung_stop()" onmouseover="samsung_start()" style="margin-top:-40px"> 
            <td style="padding:20px;width:10%;vertical-align:middle;position:relative;left:50px">
              <div class="one">
                <div class="two" id='samsung_logo'>
                  <img src='images/samsung_logo.png' width="80"></div>
              </div>
            </td>
            <td style="padding:0px;width:100%;vertical-align:top;position:relative;left:-100px">
              <a href="None">
                <papertitle><font size="4">Samsung Reseach India Bangalore (SRIB)</font></papertitle>
              </a>
              <br>
              <strong>Computer Vision Engineer</strong> 
              <br>
              <em>June 2018 - September 2020</em>
            </td>
          </tr>		
          -->  

          <!-- Btech 
          <tr onmouseout="samsung_stop()" onmouseover="samsung_start()" style="margin-top:-40px"> 
            <td style="padding:20px;width:10%;vertical-align:middle;position:relative;left:50px">
              <div class="one">
                <div class="two" id='samsung_logo'>
                  <img src='images/iitd_logo.png' width="70"></div>
              </div>
            </td>
            <td style="padding:0px;width:100%;vertical-align:top;position:relative;left:-100px">
              <a href="None">
                <papertitle><font size="4">Indian Institute of Technology, Delhi</font></papertitle>
              </a>
              <br>
              <strong>Bachelors of Technology in Mathematics and Computing</strong> 
              <br>
              <em>July 2014 - May 2018</em>
            </td>
          </tr>		 
          --> 

          <!-- Btech
          <tr onmouseout="btech_stop()" onmouseover="btech_start()" style="margin-top:-40px"> 
            <td style="padding:20px;width:60%;vertical-align:middle;position:relative;left:50px">
            </td>
          </tr>		
          -->   